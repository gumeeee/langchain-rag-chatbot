{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3cddcb03",
      "metadata": {
        "id": "3cddcb03"
      },
      "source": [
        "# Aula 7: T√©cnicas Avan√ßadas de RAG\n",
        "\n",
        "## O que vamos aprender:\n",
        "- **Hybrid Search**: Combinar a busca por palavra-chave (BM25) com a busca sem√¢ntica (FAISS) para obter o melhor dos dois mundos, usando o `EnsembleRetriever`.\n",
        "- **Multi-vector RAG**: Lidar com documentos complexos criando representa√ß√µes diferentes (resumos e chunks brutos) para uma recupera√ß√£o mais inteligente com o `MultiVectorRetriever`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc2a8085",
      "metadata": {
        "id": "cc2a8085"
      },
      "source": [
        "## 0. Configura√ß√£o\n",
        "\n",
        "Instalamos as bibliotecas e configuramos a chave de API do Google."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e82a5674",
      "metadata": {
        "id": "e82a5674",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b1f53122-fa1d-4be4-a36e-dad71b218698"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain==0.3.26\n",
            "  Downloading langchain-0.3.26-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting langchain-community==0.3.27\n",
            "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting langchain-core==0.3.71\n",
            "  Downloading langchain_core-0.3.71-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting langchain-google-genai==2.1.8\n",
            "  Downloading langchain_google_genai-2.1.8-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.6 kB)\n",
            "Collecting rank_bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain==0.3.26)\n",
            "  Downloading langchain_text_splitters-0.3.11-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.26) (0.4.59)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.26) (2.12.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.26) (2.0.45)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.26) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.26) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.27) (3.13.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.27) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community==0.3.27)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.27) (2.12.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.27) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.27) (2.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core==0.3.71) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core==0.3.71) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core==0.3.71) (25.0)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai==2.1.8)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai==2.1.8)\n",
            "  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.27) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.27) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.27) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.27) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.27) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.27) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.27) (1.22.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.27)\n",
            "  Downloading marshmallow-3.26.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.27)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai==2.1.8) (2.28.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai==2.1.8) (2.43.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai==2.1.8) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai==2.1.8) (5.29.5)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.3.71) (3.0.0)\n",
            "INFO: pip is looking at multiple versions of langchain-text-splitters to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain==0.3.26)\n",
            "  Downloading langchain_text_splitters-0.3.10-py3-none-any.whl.metadata (1.9 kB)\n",
            "  Downloading langchain_text_splitters-0.3.9-py3-none-any.whl.metadata (1.9 kB)\n",
            "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.26) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.26) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.26) (1.0.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.26) (0.12.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.26) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.26) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.26) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.26) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community==0.3.27) (1.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.3.26) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.3.26) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.3.26) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.3.26) (2025.11.12)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.26) (3.3.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai==2.1.8) (1.72.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai==2.1.8) (1.76.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai==2.1.8) (1.71.2)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai==2.1.8) (6.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai==2.1.8) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai==2.1.8) (4.9.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain==0.3.26) (4.12.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain==0.3.26) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain==0.3.26) (0.16.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.27)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai==2.1.8) (0.6.1)\n",
            "Downloading langchain-0.3.26-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.71-py3-none-any.whl (442 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m442.8/442.8 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_google_genai-2.1.8-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m47.8/47.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
            "Downloading marshmallow-3.26.2-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: filetype, rank_bm25, mypy-extensions, marshmallow, faiss-cpu, typing-inspect, dataclasses-json, langchain-core, langchain-text-splitters, google-ai-generativelanguage, langchain-google-genai, langchain, langchain-community\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 1.2.1\n",
            "    Uninstalling langchain-core-1.2.1:\n",
            "      Successfully uninstalled langchain-core-1.2.1\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 1.2.0\n",
            "    Uninstalling langchain-1.2.0:\n",
            "      Successfully uninstalled langchain-1.2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langgraph-prebuilt 1.0.5 requires langchain-core>=1.0.0, but you have langchain-core 0.3.71 which is incompatible.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 faiss-cpu-1.13.2 filetype-1.2.0 google-ai-generativelanguage-0.6.18 langchain-0.3.26 langchain-community-0.3.27 langchain-core-0.3.71 langchain-google-genai-2.1.8 langchain-text-splitters-0.3.8 marshmallow-3.26.2 mypy-extensions-1.1.0 rank_bm25-0.2.2 typing-inspect-0.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "8b2927e4af994ad780e4376aafc37a26"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install langchain==0.3.26 langchain-community==0.3.27 langchain-core==0.3.71 langchain-google-genai==2.1.8 faiss-cpu rank_bm25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ec4849dd",
      "metadata": {
        "id": "ec4849dd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ['GOOGLE_API_KEY'] = 'AIzaSyBp5ejzIoj9C374KOcJKqmCk4xJ_v9jxmo'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "21ad9fb1",
      "metadata": {
        "id": "21ad9fb1"
      },
      "outputs": [],
      "source": [
        "from langchain.schema import Document  # Importa a classe Document (texto + metadados)\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings  # LLM Gemini e embeddings\n",
        "\n",
        "# Componentes principais\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro-latest\", temperature=0)  # Instancia o Gemini 1.5 Pro determin√≠stico\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"gemini-embedding-001\")  # Modelo de embeddings do Gemini v001\n",
        "\n",
        "# Documentos de exemplo para os testes\n",
        "docs = [\n",
        "    Document(\n",
        "        page_content=\"O erro HTTP 404 Not Found ocorre quando o servidor n√£o encontra o recurso solicitado. Isso pode ser causado por uma URL digitada incorretamente ou um link quebrado.\",\n",
        "        metadata={\"source\": \"doc_http_404\"}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"SSH, ou Secure Shell, √© um protocolo que permite acesso remoto seguro a servidores. Para conectar, utilize a porta padr√£o 22 e um cliente SSH.\",\n",
        "        metadata={\"source\": \"doc_ssh_acesso_remoto\"}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Para visualizar os cont√™ineres em execu√ß√£o no Docker, use o comando 'docker ps'. Caso apare√ßa o erro 'Cannot connect to the Docker daemon', verifique se o servi√ßo do Docker est√° ativo.\",\n",
        "        metadata={\"source\": \"doc_docker_comandos\"}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"A pol√≠tica de f√©rias corporativa garante 30 dias de descanso por ano. O colaborador deve acessar o portal interno de RH e preencher o formul√°rio 'FRM-01-FERIAS' para formalizar o pedido.\",\n",
        "        metadata={\"source\": \"doc_ferias_com_formulario\"}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Para solicitar f√©rias, os colaboradores devem acessar o sistema de RH e seguir as etapas descritas no manual, preenchendo o formul√°rio correto para libera√ß√£o.\",\n",
        "        metadata={\"source\": \"doc_ferias_sem_nome_formulario\"}\n",
        "    )\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bac799df",
      "metadata": {
        "id": "bac799df"
      },
      "source": [
        "## 1. Hybrid Search com `EnsembleRetriever`\n",
        "\n",
        "A busca vetorial √© √≥tima para sem√¢ntica, mas ruim para palavras-chave. A busca por palavra-chave (BM25) √© o oposto. A busca h√≠brida une as duas. O `EnsembleRetriever` do LangChain faz isso de forma elegante.\n",
        "\n",
        "**Cen√°rio**: O usu√°rio busca pelo termo exato \"FRM-01-FERIAS\". Uma busca puramente vetorial pode n√£o dar o devido peso a esse c√≥digo espec√≠fico."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1c8c6808",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "1c8c6808"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "# Retriever de palavra-chave (Esparso)\n",
        "bm25_retriever = BM25Retriever.from_documents(docs)\n",
        "bm25_retriever.k = 2\n",
        "\n",
        "# Retriever Vetorial (Denso)\n",
        "faiss_vectorstore = FAISS.from_documents(docs, embeddings)\n",
        "faiss_retriever = faiss_vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
        "\n",
        "# Ensemble Retriever\n",
        "\n",
        "ensemble_retriever = EnsembleRetriever(\n",
        "    retrievers=[bm25_retriever, faiss_retriever],\n",
        "    weights=[0.5, 0.5]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Teste de Recupera√ß√£o ----------------------------------------------------------\n",
        "query_keyword = \"Como pe√ßo f√©rias usando o formul√°rio FRM-01-FERIAS?\"\n",
        "\n",
        "def show_results(titulo, docs, termo=\"FRM-01-FERIAS\"):\n",
        "    print(f\"\\n--- {titulo} ---\")\n",
        "    for i, d in enumerate(docs, 1):\n",
        "        src = d.metadata.get(\"source\", \"sem_source\")\n",
        "        print(f\"    {d.page_content[:120]}...\")  # descomente se quiser ver o in√≠cio do texto\n",
        "\n",
        "print(f\"--- Buscando por: '{query_keyword}' ---\")\n",
        "\n",
        "# Busca vetorial (FAISS)\n",
        "docs_faiss = faiss_retriever.invoke(query_keyword)\n",
        "show_results(\"Resultados da busca vetorial (FAISS)\", docs_faiss)\n",
        "\n",
        "# Busca h√≠brida (BM25 + FAISS via EnsembleRetriever)\n",
        "docs_ensemble = ensemble_retriever.invoke(query_keyword)\n",
        "show_results(\"Resultados da busca h√≠brida (EnsembleRetriever)\", docs_ensemble)\n",
        "\n",
        "# An√°lise autom√°tica simples\n",
        "faiss_top    = docs_faiss[0].metadata.get(\"source\")\n",
        "ensemble_top = docs_ensemble[0].metadata.get(\"source\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ALox-Zd5yyu",
        "outputId": "0e001570-164f-40df-c18e-7e6c1fa647d6"
      },
      "id": "9ALox-Zd5yyu",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Buscando por: 'Como pe√ßo f√©rias usando o formul√°rio FRM-01-FERIAS?' ---\n",
            "\n",
            "--- Resultados da busca vetorial (FAISS) ---\n",
            "    A pol√≠tica de f√©rias corporativa garante 30 dias de descanso por ano. O colaborador deve acessar o portal interno de RH ...\n",
            "    Para solicitar f√©rias, os colaboradores devem acessar o sistema de RH e seguir as etapas descritas no manual, preenchend...\n",
            "\n",
            "--- Resultados da busca h√≠brida (EnsembleRetriever) ---\n",
            "    A pol√≠tica de f√©rias corporativa garante 30 dias de descanso por ano. O colaborador deve acessar o portal interno de RH ...\n",
            "    Para solicitar f√©rias, os colaboradores devem acessar o sistema de RH e seguir as etapas descritas no manual, preenchend...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "846b8acc",
      "metadata": {
        "id": "846b8acc"
      },
      "source": [
        "## 2. Multi-vector RAG com `MultiVectorRetriever`\n",
        "\n",
        "Para documentos longos ou complexos, \"embedar\" chunks pequenos pode fazer com que o RAG perca o contexto geral. O RAG Multi-vetor resolve isso criando e buscando em resumos dos documentos primeiro, e s√≥ depois recuperando os chunks brutos para a gera√ß√£o da resposta.\n",
        "\n",
        "**Cen√°rio**: Temos um documento longo e queremos que a busca inicial considere o contexto geral do documento, n√£o apenas pequenos trechos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "6c50188a",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "6c50188a"
      },
      "outputs": [],
      "source": [
        "import uuid\n",
        "from langchain.storage import InMemoryStore\n",
        "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# Documento longo para o exemplo\n",
        "doc_longo = [\n",
        "    Document(\n",
        "        page_content=\"\"\"                                                     )\n",
        "    Introdu√ß√£o √† Seguran√ßa Cibern√©tica (2024)...\n",
        "    ...\n",
        "    Uma das t√©cnicas de ataque mais comuns √© o Phishing...\n",
        "    ...\n",
        "    Conclus√£o: Manter-se atualizado... A autentica√ß√£o de dois fatores (2FA) deve ser obrigat√≥ria.\n",
        "    \"\"\",\n",
        "        metadata={\"source\": \"guia_seguranca_ciber.pdf\", \"ano\": 2024}\n",
        "    )\n",
        "]\n",
        "\n",
        "# 1. Splitter para dividir o documento em chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300)\n",
        "doc_chunks = text_splitter.split_documents(doc_longo)\n",
        "\n",
        "# 2. Gerador de Resumos\n",
        "def generate_summaries(docs, llm_model):\n",
        "    \"\"\"Gera resumos para uma lista de documentos.\"\"\"\n",
        "    prompt = ChatPromptTemplate.from_template(\n",
        "        \"Resuma o seguinte documento em uma frase: {documento}\"\n",
        "    )\n",
        "    chain = prompt | llm_model\n",
        "    summaries = chain.batch([{\"documento\": doc.page_content} for doc in docs])\n",
        "    return [s.content for s in summaries]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Configurando o MultiVectorRetriever\n",
        "\n",
        "doc_ids = [str(uuid.uuid4()) for _ in doc_chunks]\n",
        "\n",
        "summary_chunks = generate_summaries(doc_chunks, llm)\n",
        "\n",
        "store = InMemoryStore()\n",
        "store.mset(list(zip(doc_ids, doc_chunks)))\n",
        "\n",
        "# Cria vetor-store para os resumos, carregando o id de origem do metadado\n",
        "\n",
        "summary_vectorstore = FAISS.from_texts(\n",
        "    summary_chunks,\n",
        "    embeddings,\n",
        " metadatas=[{\"doc_id\": doc_ids[i]} for i in range(len(summary_chunks))]\n",
        ")\n",
        "\n",
        "# Retriever que busca no vetor-store e devolve chunk completo via store\n",
        "\n",
        "multi_vector_retriever = MultiVectorRetriever(\n",
        "    vectorstore=summary_vectorstore,\n",
        "    docstore=store,\n",
        "    id_key=\"doc_id\",\n",
        "    search_kwargs={'k': 1}\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "7SNe30TN6Krl"
      },
      "id": "7SNe30TN6Krl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Teste de Recupera√ß√£o ---\n",
        "query_resumo = \"qual a principal defesa contra ataques cibern√©ticos?\"\n",
        "\n",
        "retrieved_docs = multi_vector_retriever.invoke(query_resumo)\n",
        "\n",
        "print(f\"--- Buscando por: '{query_resumo}' ---\\n\")\n",
        "print(\"--- Documento Original Recuperado via Resumo (MultiVectorRetriever) ---\")\n",
        "if retrieved_docs:\n",
        "    print(retrieved_docs[0].page_content)\n",
        "else:\n",
        "    print(\"No documents were retrieved.\")\n",
        "\n",
        "print(\"\\nüí° **An√°lise**: A busca foi feita nos resumos, que capturam a ess√™ncia de cada parte do documento. \"\n",
        "      \"Ao encontrar o resumo relevante sobre 'defesas', o retriever nos entregou o chunk original detalhado sobre \"\n",
        "      \"o assunto, contendo a resposta precisa.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUnyN7bk6Mog",
        "outputId": "2dcd7a69-c75a-4be6-fb39-28c2d9540465"
      },
      "id": "CUnyN7bk6Mog",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Buscando por: 'qual a principal defesa contra ataques cibern√©ticos?' ---\n",
            "\n",
            "--- Documento Original Recuperado via Resumo (MultiVectorRetriever) ---\n",
            ")\n",
            "    Introdu√ß√£o √† Seguran√ßa Cibern√©tica (2024)...\n",
            "    ...\n",
            "    Uma das t√©cnicas de ataque mais comuns √© o Phishing...\n",
            "    ...\n",
            "    Conclus√£o: Manter-se atualizado... A autentica√ß√£o de dois fatores (2FA) deve ser obrigat√≥ria.\n",
            "\n",
            "üí° **An√°lise**: A busca foi feita nos resumos, que capturam a ess√™ncia de cada parte do documento. Ao encontrar o resumo relevante sobre 'defesas', o retriever nos entregou o chunk original detalhado sobre o assunto, contendo a resposta precisa.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8c79512",
      "metadata": {
        "id": "e8c79512"
      },
      "source": [
        "## üìö Resumo Pr√°tico da Aula 7\n",
        "\n",
        "- **Hybrid Search (`EnsembleRetriever`)**: Use quando suas buscas precisarem ser boas tanto em significado (sem√¢ntica) quanto em palavras-chave (l√©xica). Essencial para buscas com c√≥digos, siglas ou nomes pr√≥prios.\n",
        "- **Multi-vector RAG (`MultiVectorRetriever`)**: A escolha ideal para documentos longos e complexos. Permite uma busca inicial mais inteligente em resumos, seguida pela recupera√ß√£o de chunks detalhados para a gera√ß√£o da resposta.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DPegmf9AKRLp"
      },
      "id": "DPegmf9AKRLp",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}